{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea50def",
   "metadata": {},
   "source": [
    "### Import the packages that are needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341585b6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel,CoherenceModel\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "from random import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np \n",
    "from joblib import dump, load \n",
    "from scipy.sparse import save_npz, load_npz \n",
    "from scipy.stats import uniform\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3011c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# inbuilt modules\n",
    "from extract_dataframe import ExtractTweets\n",
    "from clean_tweets_dataframe import TweetCleanser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d221c17",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187006d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dataframe from extracted tweets\n",
    "extracted_tweets = ExtractTweets(\"data/Economic_Twitter_Data.json\")\n",
    "df = extracted_tweets.get_tweet_df(save=False)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662d021",
   "metadata": {},
   "source": [
    "Processing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a4f38",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# clean the dataframe\n",
    "cleanser = TweetCleanser(df)\n",
    "# drop unwanted columns\n",
    "cleanser.drop_unwanted_column(df)\n",
    "# drop duplicate values from original text\n",
    "cleanser.drop_duplicate(df)\n",
    "# convert date data to appropriate datetime\n",
    "cleanser.convert_to_datetime(df)\n",
    "# remove non english texts\n",
    "df_ = cleanser.remove_non_english_tweets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f80488",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca78ff4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0be0b6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# checking for any missing values from the data\n",
    "missing_values = df_.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf1996",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361aabe8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# check the columns that have values\n",
    "columns_with_null_values = df_.columns[df_.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1625cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "columns_with_null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf8cf4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813b175",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8194a4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10bc4c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# univariate analysis on hashtags\n",
    "def get_hashtags(tweet):\n",
    "    '''This function will extract hashtags'''\n",
    "    return re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c08034",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
