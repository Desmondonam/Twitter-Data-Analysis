{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f0819f",
   "metadata": {},
   "source": [
    "## INTERIM REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669212d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5cd46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92c738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1a8a71",
   "metadata": {},
   "source": [
    "Task 3 - Data Science Level 1: \n",
    "Here you are required to write the code base necessary to do data analysis and produce a machine learning model to perform topic modelling and sentiment analysis.\n",
    "\n",
    "You are required to write the following modules at the minimum:\n",
    "\n",
    "* Data exploration and pre-processing: the codes you fixed at step 1 are the modules you will extend to perform data reading, pre-processing and data exploration and visualisations\n",
    "* Topic modelling and sentiment analysis: write a code using scikit-learn, Gensim, or other packages and APIs to model the topics discussed in the tweets and their sentiments. You may use word clouds, k-mean clustering, etc. as a simple model for topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3e6cc",
   "metadata": {},
   "source": [
    "## Load the required libraries for the data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import re\n",
    "import string\n",
    "\n",
    "# visualization\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# natural Language processing\n",
    "import spacy\n",
    "import gensim\n",
    "import spacy.tokenizer import Tokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b287e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac4834b",
   "metadata": {},
   "source": [
    "## Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee2c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3136a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ad095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ef777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a79909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01a2d20d",
   "metadata": {},
   "source": [
    "## Topic Modelling and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ace808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a id2word dictionary\n",
    "id2word = Dictionary(df['lemma_tokens'])\n",
    "print(len(id2word))\n",
    "In [ ]:\n",
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))\n",
    "In [ ]:\n",
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]\n",
    "In [ ]:\n",
    "# Instantiating a Base LDA model \n",
    "base_model = LdaMulticore(corpus=corpus, num_topics=5, id2word=id2word, workers=12, passes=5)\n",
    "In [ ]:\n",
    "# Filtering for words \n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n",
    "In [ ]:\n",
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]\n",
    "In [ ]:\n",
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
